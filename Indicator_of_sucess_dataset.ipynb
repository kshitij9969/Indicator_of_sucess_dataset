{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Indicator_of_sucess_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1n9ItL-6meyEG5sZeaTbBahaHiow2z2RU",
      "authorship_tag": "ABX9TyNS4OjHf6hg+ku2T7e7NXM+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kshitij9969/Indicator_of_sucess_dataset/blob/main/Indicator_of_sucess_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x9hQzWkCV8a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To do: \n",
        "# Two types of data needs to be extracted\n",
        "# 1. Indexes\n",
        "# 2. True values\n",
        "\n",
        "# 1. Cost of living index by city\n",
        "# 2. Cost of living index by country\n",
        "# 3. Property price index\n",
        "# 4. Quality of life index\n",
        "# 5. Crime index\n",
        "# 6. Health care index\n",
        "# 7. Pollution index\n",
        "# 8. Traffic index\n",
        "# 9. \n",
        "\n",
        "\n",
        "# 3. Cost of living estimator by city\n",
        "# 4. Food prices by city\n",
        "# 5. Food prices by country\n",
        "# 6. Prices of other commodity by city and country\n",
        "# 7. Basket of prices by city\n",
        "# 8. Taxi fare by city\n",
        "# 9. Gas prices by city\n"
      ],
      "metadata": {
        "id": "ysqfm0ZEjZrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cost of living index\n",
        "\n",
        "### Cost of living index over the years. "
      ],
      "metadata": {
        "id": "ebCgZ-JeF_X2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(\"https://www.numbeo.com/cost-of-living/rankings.jsp\")"
      ],
      "metadata": {
        "id": "IO2nzA_ACuNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_html(response.text)"
      ],
      "metadata": {
        "id": "ltyBnHXoHj-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "gimEa2-HHu6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.text, 'html.parser')"
      ],
      "metadata": {
        "id": "nmWVT-MEHvJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = soup.find(\"table\", attrs={\"id\": \"t2\"})"
      ],
      "metadata": {
        "id": "hO-xqtzaH5hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_html(str(table))[0]"
      ],
      "metadata": {
        "id": "IIzoaUf-IFVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning columns\n",
        "\n",
        "for col in df.columns:\n",
        "    df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n"
      ],
      "metadata": {
        "id": "CYavwSE1IGM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split city and country\n",
        "\n",
        "df['Country'] = df['City'].apply(lambda x: x.split(\", \")[-1].strip())"
      ],
      "metadata": {
        "id": "B7XzaqFHITXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['City'] = df['City'].apply(lambda x: x.split(\", \")[0].strip())"
      ],
      "metadata": {
        "id": "_FqOV_YkJbiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "NrVaCBRAK27J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Rank'] = df['index']"
      ],
      "metadata": {
        "id": "X4-CjcOxMISr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['index'], inplace=True)"
      ],
      "metadata": {
        "id": "5UeBHl_4MSvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Rank'] = df['Rank'].apply(lambda x: x + 1)"
      ],
      "metadata": {
        "id": "UMRbmHOuMXT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Year'] = 2021\n",
        "df['Month'] = 6\n",
        "df['Day'] = 1"
      ],
      "metadata": {
        "id": "iqa3MhePMdJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])"
      ],
      "metadata": {
        "id": "MqmrCZtIMihg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from requests.api import request\n",
        "# Now collect for all other years and months\n",
        "\n",
        "# Country links: \n",
        "links = [\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=2021&region=002\", \"Africa\"), # Africa\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=2021&region=019\", \"America\"), # America\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=2021&region=142\", \"Asia\"), # Asia\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=2021&region=150\", \"Europe\"), # Europe\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=2021&region=009\", \"Oceania\") # Oceania\n",
        "]\n",
        "\n",
        "# Collecting links for regions\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Continent', 'Region', \n",
        "                                        'Cost_of_Living_Index', 'Rent_Index',\n",
        "                                        'Cost_of_Living_Plus_Rent_Index', \n",
        "                                        'Groceries_Index', \n",
        "                                        'Restaurant_Price_Index', \n",
        "                                        'Local_Purchasing_Power_Index', 'Year', \n",
        "                                        'Month', 'Day', 'Date'])\n",
        "\n",
        "years_list = ['2021-mid', '2021', '2020-mid', '2020', '2019-mid', '2019', '2018-mid', '2018', '2017-mid', '2017', '2016-mid', '2016', '2015-mid', '2015', '2014-mid', '2014', '2013', '2012', '2011', '2010', '2009']\n",
        "\n",
        "for (i, continent) in links:\n",
        "    res = requests.get(i)\n",
        "    soup = BeautifulSoup(res.text)\n",
        "    try:\n",
        "        spans = soup.find(\"div\", attrs={\"class\": \"select_region_links\"}).find_all(\"span\", attrs={\"class\": \"nobreak\"})\n",
        "    except Exception as e:\n",
        "        # Oceania doesn't have any regions\n",
        "        print(e)\n",
        "        print(i)\n",
        "    print(spans)\n",
        "    for span in spans:\n",
        "        url = span.find(\"a\", href=True)['href']\n",
        "        resp = requests.get(url)\n",
        "        soup1 = BeautifulSoup(resp.text)\n",
        "        # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "        # print(resp.text)\n",
        "        table = soup.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "        df = pd.read_html(str(table))[0]\n",
        "        # Clean columns\n",
        "        for col in df.columns:\n",
        "            df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "        \n",
        "        # Correct Rank\n",
        "        df.reset_index(inplace=True)\n",
        "        df['Rank'] = df['index']\n",
        "        df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "        df.drop(columns=['index'], inplace=True)\n",
        "        # Add month year and day\n",
        "        df['Year'] = 2021\n",
        "        df['Month'] = 1\n",
        "        df['Day'] = 1\n",
        "\n",
        "        df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "        # Add country and continent\n",
        "        df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "        df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "        df['Continent'] = continent\n",
        "        df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "        print(url)\n",
        "        print(years_list)\n",
        "    break\n",
        "        # print(url)\n",
        "        # print(years_list)\n",
        "        # region_name = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "        # print(region_name)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8w52NS1qNCJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from requests.api import request\n",
        "# Now collect for all other years and months\n",
        "\n",
        "# Country links: \n",
        "links = [\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=year&region=002\", \"Africa\"), # Africa\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=year&region=019\", \"America\"), # America\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=year&region=142\", \"Asia\"), # Asia\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=year&region=150\", \"Europe\"), # Europe\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=year&region=009\", \"Oceania\") # Oceania\n",
        "]\n",
        "\n",
        "# Collecting links for regions\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Continent', 'Region', \n",
        "                                        'Cost_of_Living_Index', 'Rent_Index',\n",
        "                                        'Cost_of_Living_Plus_Rent_Index', \n",
        "                                        'Groceries_Index', \n",
        "                                        'Restaurant_Price_Index', \n",
        "                                        'Local_Purchasing_Power_Index', 'Year', \n",
        "                                        'Month', 'Day', 'Date'])\n",
        "\n",
        "years_list = ['2021-mid', '2021', '2020-mid', '2020', '2019-mid', '2019', \n",
        "              '2018-mid', '2018', '2017-mid', '2017', '2016-mid', '2016', \n",
        "              '2015-mid', '2015', '2014-mid', '2014', '2013', '2012', \n",
        "              '2011', '2010', '2009']\n",
        "url_list = []\n",
        "\n",
        "for year in years_list:\n",
        "    for (i, continent) in links:\n",
        "        res = requests.get(i.replace(\"year\", year))\n",
        "        soup = BeautifulSoup(res.text)\n",
        "        try:\n",
        "            spans = soup.find(\"div\", attrs={\"class\": \"select_region_links\"}).find_all(\"span\", attrs={\"class\": \"nobreak\"})\n",
        "        except Exception as e:\n",
        "            # Oceania doesn't have any regions\n",
        "            print(e)\n",
        "            print(i)\n",
        "        for span in spans:\n",
        "            url = span.find(\"a\", href=True)['href']\n",
        "            url_list.append(url)\n",
        "print(url_list)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oJgOJzxjNVoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_list"
      ],
      "metadata": {
        "id": "llNrTq3rioe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Continent', 'Region', \n",
        "                                        'Cost_of_Living_Index', 'Rent_Index',\n",
        "                                        'Cost_of_Living_Plus_Rent_Index', \n",
        "                                        'Groceries_Index', \n",
        "                                        'Restaurant_Price_Index', \n",
        "                                        'Local_Purchasing_Power_Index', 'Year', \n",
        "                                        'Month', 'Day', 'Date', 'URL'])\n",
        "for url in url_list:\n",
        "    resp = requests.get(url)\n",
        "    print(url)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    \n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    df['Continent'] = continent\n",
        "    df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df)\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "-tZJi40M_oCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe[final_dataframe.Year == 2015]"
      ],
      "metadata": {
        "id": "pzAJnoEn_5E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correcting the Continent\n",
        "\n",
        "\n",
        "def get_continent(x):\n",
        "    if \"Africa\" in x:\n",
        "        return \"Africa\"\n",
        "    elif \"America\" in x:\n",
        "        return \"America\"\n",
        "    elif \"Oceania\" in x:\n",
        "        return \"Oceania\"\n",
        "    elif \"Asia\" in x:\n",
        "        return \"Asia\"\n",
        "    else:\n",
        "        return \"Europe\"\n",
        "\n",
        "final_dataframe['Continent'] = final_dataframe['Region'].apply(lambda x: get_continent(x))"
      ],
      "metadata": {
        "id": "TPeMo5Py_58-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe[(final_dataframe.City == \"Aachen\") & (final_dataframe.duplicated() == True)].sort_values(by=\"City\")"
      ],
      "metadata": {
        "id": "V2wjArKCEB-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "Xdzq8pp_EC4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.drop_duplicates(subset=['City', 'Country', 'Continent', 'Region', 'Year', 'Month', 'Day', 'Date'])"
      ],
      "metadata": {
        "id": "xCbBnc9XSZsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Cost_of_living_index.csv\", index=False)"
      ],
      "metadata": {
        "id": "QghGRLqhT-Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "property_url_list = [i.replace(\"cost-of-living\", \"property-investment\") for i in url_list]"
      ],
      "metadata": {
        "id": "ZwjS5kCJXkWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Property index\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Continent', 'Region', \n",
        "                                        'Price_To_Income_Ratio',\n",
        "                                        'Gross_Rental_Yield_City_Centre',\n",
        "                                        'Gross_Rental_Yield_Outside_of_Centre',\n",
        "                                        'Price_To_Rent_Ratio_City_Centre',\n",
        "                                        'Price_To_Rent_Ratio_Outside_Of_City_Centre',\n",
        "                                        'Mortgage_As_A_Percentage_Of_Income',\n",
        "                                        'Affordability_Index', 'Year', \n",
        "                                        'Month', 'Day', 'Date', 'URL'])\n",
        "for url in property_url_list:\n",
        "    resp = requests.get(url)\n",
        "    print(url)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    \n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    df['Continent'] = continent\n",
        "    df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yQCJ-uH8Ugy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe['Continent'] = final_dataframe.Region.apply(lambda x: get_continent(x))"
      ],
      "metadata": {
        "id": "H2tCoY-aUpsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Property_price_index.csv\", index=False)"
      ],
      "metadata": {
        "id": "_FIeDAuBYemc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe"
      ],
      "metadata": {
        "id": "YaQiAkOaYlv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Property price index by country\n",
        "\n",
        "# Property index\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'Country', \n",
        "                                        'Price_To_Income_Ratio',\n",
        "                                        'Gross_Rental_Yield_City_Centre',\n",
        "                                        'Gross_Rental_Yield_Outside_of_Centre',\n",
        "                                        'Price_To_Rent_Ratio_City_Centre',\n",
        "                                        'Price_To_Rent_Ratio_Outside_Of_City_Centre',\n",
        "                                        'Mortgage_As_A_Percentage_Of_Income',\n",
        "                                        'Affordability_Index', 'Year', \n",
        "                                        'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/property-investment/rankings_by_country.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    print(df)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    # df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    # df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n"
      ],
      "metadata": {
        "id": "8_qKq8Oigeay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Property_price_index_by_country.csv\", index=False)"
      ],
      "metadata": {
        "id": "96BjaG3AiV_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quality of life index by country and city\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Quality_of_Life_Index', \n",
        "                                        'Purchasing_Power_Index', \n",
        "                                        'Safety_Index', 'Health_Care_Index', \n",
        "                                        'Cost_of_Living_Index', \n",
        "                                        'Property_Price_to_Income_Ratio', \n",
        "                                        'Traffic_Commute_Time_Index', \n",
        "                                        'Pollution_Index', 'Climate_Index', \n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/quality-of-life/rankings.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    print(df.columns)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v9CpokiKjulV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "omu869wJlm3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Quality_of_life_index_by_city.csv\", index=False)"
      ],
      "metadata": {
        "id": "sTEeyURgnI56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quality of life index by country\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'Country', \n",
        "                                        'Quality_of_Life_Index', \n",
        "                                        'Purchasing_Power_Index', \n",
        "                                        'Safety_Index', 'Health_Care_Index', \n",
        "                                        'Cost_of_Living_Index', \n",
        "                                        'Property_Price_to_Income_Ratio', \n",
        "                                        'Traffic_Commute_Time_Index', \n",
        "                                        'Pollution_Index', 'Climate_Index', \n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/quality-of-life/rankings_by_country.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    print(df.columns)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    # df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    # df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2mgRVzCOo86J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Quality_of_life_index_by_country.csv\", index=False)"
      ],
      "metadata": {
        "id": "6Y6FmL5StTZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crime index by country and city\n",
        "\n",
        "# Quality of life index by country and city\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Crime_Index', 'Safety_Index', \n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/crime/rankings.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EWTBlEv-tWay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Crime_index_by_city.csv\", index=False)"
      ],
      "metadata": {
        "id": "I0xwLRInwP76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crime index by country\n",
        "\n",
        "# Quality of life index by country\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'Country', \n",
        "                                        'Crime_Index', 'Safety_Index', \n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/crime/rankings_by_country.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    print(df.columns)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    # df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    # df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "XGkXNh5gwf1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Crime_index_by_country.csv\", index=False)"
      ],
      "metadata": {
        "id": "0p2yGMU6w_14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Health care index by country and city\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Health_Care_Index', 'Health_CareExp_Index',\n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/health-care/rankings.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join([i.replace(\".\", \"\") for i in col.split(\" \")])}, inplace=True)\n",
        "    \n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sA1toc7NyAgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Health_care_index_by_city.csv\", index=False)"
      ],
      "metadata": {
        "id": "KhNA6pYIzbJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Health index by country\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'Country', \n",
        "                                        'Health_Care_Index', 'Health_CareExp_Index',\n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/health-care/rankings_by_country.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join([i.replace(\".\", \"\") for i in col.split(\" \")])}, inplace=True)\n",
        "    print(df.columns)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    # df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    # df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "0UVI0fyhy3mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Health_index_by_country.csv\", index=False)"
      ],
      "metadata": {
        "id": "xItaOCZq1476"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pollution index by country and city\n",
        "\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Pollution_Index', 'Exp_Pollution_Index',\n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/pollution/rankings.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join([i.replace(\".\", \"\") for i in col.split(\" \")])}, inplace=True)\n",
        "    \n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "airdplqV3udf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Pollution_index_by_city.csv\", index=False)"
      ],
      "metadata": {
        "id": "srGL3K9N7HlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pollution index by country\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'Country', \n",
        "                                        'Pollution_Index', 'Exp_Pollution_Index',\n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/pollution/rankings_by_country.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join([i.replace(\".\", \"\") for i in col.split(\" \")])}, inplace=True)\n",
        "    print(df.columns)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    # df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    # df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PFY8Egn87Yxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Pollution_index_by_country.csv\", index=False)"
      ],
      "metadata": {
        "id": "mcdWwamV8I6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OUSOBXx98Xhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "files=os.listdir(\"/content/\")\n",
        "\n",
        "def save_to_drive():\n",
        "    # iterating over all the files in\n",
        "    # the source directory\n",
        "    for fname in files:\n",
        "        if \".csv\" in fname:\n",
        "            shutil.copy2(os.path.join(\"/content/\",fname), \"/content/drive/MyDrive/Indicator_of_success_dataset/\")"
      ],
      "metadata": {
        "id": "RP9NHJ9r1WOf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Traffic index by country and city\n",
        "\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Traffic_Index', 'Time_Index_in_minutes',\n",
        "                                        'Time_Exp_Index', 'Inefficiency_Index', 'CO2_Emission_Index', \n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/traffic/rankings.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join([i.replace(\".\", \"\") for i in col.split(\" \")])}, inplace=True)\n",
        "    \n",
        "    df.rename(columns={\"Time_Index(in_minutes)\": \"Time_Index_in_minutes\"}, inplace=True)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VQK56LJ01xmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Traffic_index_by_city.csv\", index=False)"
      ],
      "metadata": {
        "id": "-fO6nQRAFSLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Traffic index by country\n",
        "\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'Country', \n",
        "                                        'Traffic_Index', 'Time_Index_in_minutes',\n",
        "                                        'Time_Exp_Index', 'Inefficiency_Index', 'CO2_Emission_Index',\n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/traffic/rankings_by_country.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join([i.replace(\".\", \"\") for i in col.split(\" \")])}, inplace=True)\n",
        "    print(df.columns)\n",
        "    df.rename(columns={\"Time_Index(in_minutes)\": \"Time_Index_in_minutes\"}, inplace=True)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    # df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    # df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hDkBAof-GCdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Traffic_index_by_country.csv\", index=False)"
      ],
      "metadata": {
        "id": "Uud8MA0vJjYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost of living true values by country"
      ],
      "metadata": {
        "id": "VFEmPBFdLDRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "response = requests.get(\"https://www.numbeo.com/cost-of-living/\")\n",
        "\n",
        "soup2 = BeautifulSoup(response.text)\n",
        "\n",
        "tds = soup2.find(\"table\", attrs={\"class\": \"related_links\"}).find(\"tr\").find_all(\"td\")\n",
        "\n",
        "a = [td.find_all(\"a\", href=True) for td in tds]\n",
        "\n",
        "links = []\n",
        "\n",
        "for i in a:\n",
        "    for j in i:\n",
        "        links.append([j['href'], j.text])\n",
        "\n"
      ],
      "metadata": {
        "id": "f5jPNIlQLInB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe = pd.DataFrame(columns=['Commodity', 'Price', 'Lower_Range', 'Upper_Range'])\n",
        "for [link, country] in links:\n",
        "    response = requests.get(\"https://www.numbeo.com/cost-of-living/\" + link)\n",
        "    soup3 = BeautifulSoup(response.text)\n",
        "    table = soup3.find(\"table\", attrs={\"class\": \"data_wide_table new_bar_table\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    df['Country'] = country\n",
        "    df = df[df['Edit'] != 'Edit']\n",
        "    df.rename(columns={\"Restaurants\": \"Commodity\", \"Edit\": \"Price\"}, inplace=True)\n",
        "    # df['Currency'] = df['Price'].apply(lambda x: str(x.split(\" \")[-1].strip()) if str(x) != 'nan' else x)\n",
        "    # df['Price'] = df['Price'].apply(lambda x: float(x.split(\" \")[0].strip()) if str(x) != 'nan' else x)\n",
        "    df['Lower_Range'] = df['Range'].apply(lambda x: float(str(x).split(\"-\")[0].strip()) if str(x) != 'nan' else x)\n",
        "    df['Upper_Range'] = df['Range'].apply(lambda x: float(str(x).split(\"-\")[1].strip()) if str(x) != 'nan' else x)\n",
        "    final_dataframe = final_dataframe.append(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6xFK4MNLRR8",
        "outputId": "c60ab878-b055-4df8-aa0d-c7bb3e4298e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_dataframe.Country.unique())"
      ],
      "metadata": {
        "id": "iMXRSYUsLSM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Cost_of_living_by_country.csv\", index=False)"
      ],
      "metadata": {
        "id": "_bGzT2QINeOV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Food prices by country\n",
        "\n",
        "import re\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=[\"Commodity\", \"Country\", \"Quantity\", \"Unit\", \"Price\"])\n",
        "\n",
        "for link in links:\n",
        "    response = requests.get(\"https://www.numbeo.com/food-prices/\" + link[0])\n",
        "    soup4 = BeautifulSoup(response.text)\n",
        "    table = soup4.find_all(\"table\")[1]\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    df = df.iloc[:-2]\n",
        "    df.rename(columns={0: \"Commodity\", 1: \"Price\"}, inplace=True)\n",
        "    df['Quantity'] = df[\"Commodity\"].apply(lambda x: re.findall(r\"\\([a-zA-Z0-9(\\.)+ ]+\\)$\", x.strip())[-1])\n",
        "    df['Quantity'] = df['Quantity'].apply(lambda x: x.split(\") (\"))\n",
        "    df['Quantity'] = df['Quantity'].apply(lambda x: [i for i in x if bool(re.search(\"[0-9]+\", i))])\n",
        "    df['Quantity'] = df['Quantity'].apply(lambda x: x[0].strip(\"(\").strip(\")\"))\n",
        "    df['Unit'] =df['Quantity'].apply(lambda x: x.split(\" \")[-1] if len(x.split(\" \")) > 1 else np.nan)\n",
        "    df['Quantity'] =df['Quantity'].apply(lambda x: x.split(\" \")[0] if len(x.split(\" \")) > 1 else x)\n",
        "    df['Country'] = link[-1]\n",
        "    # df['Quantity'] = df['Quantity'].apply(lambda x: x.split(\",\"))\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "    # break\n",
        "\n"
      ],
      "metadata": {
        "id": "HOMvpLghKEhI"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "B0Q1Cis_svt6",
        "outputId": "dbe13f6a-9380-48d4-88f9-891a3cd1d40d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dd087134-ecdd-4a4f-b34c-15de5939fb61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Commodity</th>\n",
              "      <th>Country</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Unit</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Milk (regular), (0.25 liter)</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>0.25</td>\n",
              "      <td>liter</td>\n",
              "      <td>13.03 AFN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Loaf of Fresh White Bread (125.00 g)</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>125.00</td>\n",
              "      <td>g</td>\n",
              "      <td>8.04 AFN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rice (white), (0.10 kg)</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>0.10</td>\n",
              "      <td>kg</td>\n",
              "      <td>9.33 AFN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Eggs (regular) (2.40)</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2.40</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.68 AFN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Local Cheese (0.10 kg)</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>0.10</td>\n",
              "      <td>kg</td>\n",
              "      <td>31.49 AFN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Oranges (0.30 kg)</td>\n",
              "      <td>Zimbabwe</td>\n",
              "      <td>0.30</td>\n",
              "      <td>kg</td>\n",
              "      <td>0.59 $</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Tomato (0.20 kg)</td>\n",
              "      <td>Zimbabwe</td>\n",
              "      <td>0.20</td>\n",
              "      <td>kg</td>\n",
              "      <td>0.32 $</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Potato (0.20 kg)</td>\n",
              "      <td>Zimbabwe</td>\n",
              "      <td>0.20</td>\n",
              "      <td>kg</td>\n",
              "      <td>0.36 $</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Onion (0.10 kg)</td>\n",
              "      <td>Zimbabwe</td>\n",
              "      <td>0.10</td>\n",
              "      <td>kg</td>\n",
              "      <td>0.16 $</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Lettuce (0.20 head)</td>\n",
              "      <td>Zimbabwe</td>\n",
              "      <td>0.20</td>\n",
              "      <td>head</td>\n",
              "      <td>0.18 $</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3276 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd087134-ecdd-4a4f-b34c-15de5939fb61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd087134-ecdd-4a4f-b34c-15de5939fb61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd087134-ecdd-4a4f-b34c-15de5939fb61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               Commodity      Country  ...   Unit      Price\n",
              "0           Milk (regular), (0.25 liter)  Afghanistan  ...  liter  13.03 AFN\n",
              "1   Loaf of Fresh White Bread (125.00 g)  Afghanistan  ...      g   8.04 AFN\n",
              "2                Rice (white), (0.10 kg)  Afghanistan  ...     kg   9.33 AFN\n",
              "3                  Eggs (regular) (2.40)  Afghanistan  ...    NaN  20.68 AFN\n",
              "4                 Local Cheese (0.10 kg)  Afghanistan  ...     kg  31.49 AFN\n",
              "..                                   ...          ...  ...    ...        ...\n",
              "9                      Oranges (0.30 kg)     Zimbabwe  ...     kg     0.59 $\n",
              "10                      Tomato (0.20 kg)     Zimbabwe  ...     kg     0.32 $\n",
              "11                      Potato (0.20 kg)     Zimbabwe  ...     kg     0.36 $\n",
              "12                       Onion (0.10 kg)     Zimbabwe  ...     kg     0.16 $\n",
              "13                   Lettuce (0.20 head)     Zimbabwe  ...   head     0.18 $\n",
              "\n",
              "[3276 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Food_prices_by_country.csv\", index=False)\n",
        "save_to_drive()"
      ],
      "metadata": {
        "id": "SMAJtV4EuvxI"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(\"2.40\".split(\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtcygNVpyiaF",
        "outputId": "eda5ec3d-8cd7-4193-92b7-559e5c6088ce"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prices of other commodities by country and city\n",
        "\n",
        "url = \"https://www.numbeo.com/cost-of-living/prices_by_city.jsp\"\n",
        "\n",
        "# Get all the item ids\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "soup5 = BeautifulSoup(response.text)\n",
        "\n",
        "option = soup5.find(\"table\", attrs={\"class\": \"table_for_selecting_items\"}).find_all(\"tr\")[1].find_all(\"td\")[-1].find(\"select\").find_all(\"option\")\n",
        "\n",
        "\n",
        "\n",
        "item_ids = [i['value'] for i in option]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R6m0xKT_8uxf"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe = pd.DataFrame()\n",
        "url = f\"https://www.numbeo.com/cost-of-living/prices_by_city.jsp?displayCurrency=USD&itemId={item_id}\"\n",
        "response = requests.get(url)\n",
        "soup6 = BeautifulSoup(response.text)\n",
        "table = soup6.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "final_dataframe = pd.read_html(str(table))[0]\n",
        "# final_dataframe['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "# final_dataframe['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "# final_dataframe['Currency'] = \"$\"\n",
        "final_dataframe.drop(columns=['Rank'], inplace=True)\n",
        "for item_id in item_ids[1:]:\n",
        "    url = f\"https://www.numbeo.com/cost-of-living/prices_by_city.jsp?displayCurrency=USD&itemId={item_id}\"\n",
        "    response = requests.get(url)\n",
        "    soup6 = BeautifulSoup(response.text)\n",
        "    table = soup6.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    df.drop(columns=\"Rank\", inplace=True)\n",
        "    # df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    # df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Currency'] = \"$\"\n",
        "    final_dataframe = pd.merge(final_dataframe, df, on=\"City\", how=\"outer\")"
      ],
      "metadata": {
        "id": "AqxNQaorNQFt"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe['Country'] = final_dataframe['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "final_dataframe['City'] = final_dataframe['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "final_dataframe['Currency'] = \"$\"\n",
        "final_dataframe.to_csv(\"Price_of_other_commodities_by_city.csv\", index=False)\n",
        "save_to_drive()"
      ],
      "metadata": {
        "id": "2hyFpqRkNRGt"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taxi fare by country\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "response = requests.get(\"https://www.numbeo.com/taxi-fare/\")\n",
        "\n",
        "soup7 = BeautifulSoup(response.text)\n",
        "tds = soup7.find(\"table\", attrs={\"class\": \"related_links\"}).find(\"tr\").find_all(\"td\")\n",
        "\n",
        "links = []\n",
        "\n",
        "for td in tds:\n",
        "    links.extend([(a['href'], a.text) for a in td.find_all(\"a\", href=True)])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0HJyCq9QP-MJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "final_dataframe = pd.DataFrame(columns=['City', 'Taxi Start(Normal Tariff)', 'Taxi 1km(Normal Tariff)',\n",
        "       'Taxi 1hour waiting(Normal Tariff)'])\n",
        "for link in links:\n",
        "    url = \"https://www.numbeo.com/taxi-fare/\"\n",
        "    response = requests.get(url + link[0])\n",
        "    table = BeautifulSoup(response.text).find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    final_dataframe = final_dataframe.append(df)"
      ],
      "metadata": {
        "id": "0jJTdWxtS3BE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe['Currency'] = final_dataframe['Taxi Start(Normal Tariff)'].apply(lambda x: x.split(\" \")[-1].strip())\n",
        "# for col in final_dataframe.columns:\n",
        "#     if col != \"City\":\n",
        "#         final_dataframe[col] = final_dataframe[col].apply(lambda x: float(x.replace(u'\\xa0', u' ').split(\" \")[0].strip().replace(\",\", \"\")))"
      ],
      "metadata": {
        "id": "fIcR_tgBS34Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe['Currency'] = final_dataframe['Taxi Start(Normal Tariff)'].apply(lambda x: str(x).split(\" \")[-1])"
      ],
      "metadata": {
        "id": "-aAo_23jVbGM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Taxi_fare_by_city.csv\", index=False)\n",
        "save_to_drive()"
      ],
      "metadata": {
        "id": "X9he2-J_OIK7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C306txBR0YK",
        "outputId": "9ca4d0df-6e1c-4455-a68d-064f84471fd1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "City                                 object\n",
              "Taxi Start(Normal Tariff)            object\n",
              "Taxi 1km(Normal Tariff)              object\n",
              "Taxi 1hour waiting(Normal Tariff)    object\n",
              "Currency                             object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qy9XwMudR6VI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}