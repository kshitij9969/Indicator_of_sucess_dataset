{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Indicator_of_sucess_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1n9ItL-6meyEG5sZeaTbBahaHiow2z2RU",
      "authorship_tag": "ABX9TyMN+bMDIF+7gKE/2B4PtghH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kshitij9969/Indicator_of_sucess_dataset/blob/main/Indicator_of_sucess_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x9hQzWkCV8a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To do: \n",
        "# Two types of data needs to be extracted\n",
        "# 1. Indexes\n",
        "# 2. True values\n",
        "\n",
        "# 1. Cost of living index by city\n",
        "# 2. Cost of living index by country\n",
        "# 3. Property price index\n",
        "# 4. Quality of life index\n",
        "# 5. Crime index\n",
        "# 6. Health care index\n",
        "# 7. Pollution index\n",
        "# 8. Traffic index\n",
        "# 9. \n",
        "\n",
        "\n",
        "# 3. Cost of living estimator by city\n",
        "# 4. Food prices by city\n",
        "# 5. Food prices by country\n",
        "# 6. Prices of other commodity by city and country\n",
        "# 7. Basket of prices by city\n",
        "# 8. Taxi fare by city\n",
        "# 9. Gas prices by city\n"
      ],
      "metadata": {
        "id": "ysqfm0ZEjZrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cost of living index\n",
        "\n",
        "### Cost of living index over the years. "
      ],
      "metadata": {
        "id": "ebCgZ-JeF_X2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(\"https://www.numbeo.com/cost-of-living/rankings.jsp\")"
      ],
      "metadata": {
        "id": "IO2nzA_ACuNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_html(response.text)"
      ],
      "metadata": {
        "id": "ltyBnHXoHj-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "gimEa2-HHu6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.text, 'html.parser')"
      ],
      "metadata": {
        "id": "nmWVT-MEHvJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table = soup.find(\"table\", attrs={\"id\": \"t2\"})"
      ],
      "metadata": {
        "id": "hO-xqtzaH5hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_html(str(table))[0]"
      ],
      "metadata": {
        "id": "IIzoaUf-IFVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning columns\n",
        "\n",
        "for col in df.columns:\n",
        "    df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n"
      ],
      "metadata": {
        "id": "CYavwSE1IGM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split city and country\n",
        "\n",
        "df['Country'] = df['City'].apply(lambda x: x.split(\", \")[-1].strip())"
      ],
      "metadata": {
        "id": "B7XzaqFHITXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['City'] = df['City'].apply(lambda x: x.split(\", \")[0].strip())"
      ],
      "metadata": {
        "id": "_FqOV_YkJbiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "NrVaCBRAK27J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Rank'] = df['index']"
      ],
      "metadata": {
        "id": "X4-CjcOxMISr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['index'], inplace=True)"
      ],
      "metadata": {
        "id": "5UeBHl_4MSvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Rank'] = df['Rank'].apply(lambda x: x + 1)"
      ],
      "metadata": {
        "id": "UMRbmHOuMXT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Year'] = 2021\n",
        "df['Month'] = 6\n",
        "df['Day'] = 1"
      ],
      "metadata": {
        "id": "iqa3MhePMdJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])"
      ],
      "metadata": {
        "id": "MqmrCZtIMihg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from requests.api import request\n",
        "# Now collect for all other years and months\n",
        "\n",
        "# Country links: \n",
        "links = [\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=2021&region=002\", \"Africa\"), # Africa\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=2021&region=019\", \"America\"), # America\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=2021&region=142\", \"Asia\"), # Asia\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=2021&region=150\", \"Europe\"), # Europe\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=2021&region=009\", \"Oceania\") # Oceania\n",
        "]\n",
        "\n",
        "# Collecting links for regions\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Continent', 'Region', \n",
        "                                        'Cost_of_Living_Index', 'Rent_Index',\n",
        "                                        'Cost_of_Living_Plus_Rent_Index', \n",
        "                                        'Groceries_Index', \n",
        "                                        'Restaurant_Price_Index', \n",
        "                                        'Local_Purchasing_Power_Index', 'Year', \n",
        "                                        'Month', 'Day', 'Date'])\n",
        "\n",
        "years_list = ['2021-mid', '2021', '2020-mid', '2020', '2019-mid', '2019', '2018-mid', '2018', '2017-mid', '2017', '2016-mid', '2016', '2015-mid', '2015', '2014-mid', '2014', '2013', '2012', '2011', '2010', '2009']\n",
        "\n",
        "for (i, continent) in links:\n",
        "    res = requests.get(i)\n",
        "    soup = BeautifulSoup(res.text)\n",
        "    try:\n",
        "        spans = soup.find(\"div\", attrs={\"class\": \"select_region_links\"}).find_all(\"span\", attrs={\"class\": \"nobreak\"})\n",
        "    except Exception as e:\n",
        "        # Oceania doesn't have any regions\n",
        "        print(e)\n",
        "        print(i)\n",
        "    print(spans)\n",
        "    for span in spans:\n",
        "        url = span.find(\"a\", href=True)['href']\n",
        "        resp = requests.get(url)\n",
        "        soup1 = BeautifulSoup(resp.text)\n",
        "        # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "        # print(resp.text)\n",
        "        table = soup.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "        df = pd.read_html(str(table))[0]\n",
        "        # Clean columns\n",
        "        for col in df.columns:\n",
        "            df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "        \n",
        "        # Correct Rank\n",
        "        df.reset_index(inplace=True)\n",
        "        df['Rank'] = df['index']\n",
        "        df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "        df.drop(columns=['index'], inplace=True)\n",
        "        # Add month year and day\n",
        "        df['Year'] = 2021\n",
        "        df['Month'] = 1\n",
        "        df['Day'] = 1\n",
        "\n",
        "        df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "        # Add country and continent\n",
        "        df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "        df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "        df['Continent'] = continent\n",
        "        df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "        print(url)\n",
        "        print(years_list)\n",
        "    break\n",
        "        # print(url)\n",
        "        # print(years_list)\n",
        "        # region_name = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "        # print(region_name)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8w52NS1qNCJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from requests.api import request\n",
        "# Now collect for all other years and months\n",
        "\n",
        "# Country links: \n",
        "links = [\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=year&region=002\", \"Africa\"), # Africa\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=year&region=019\", \"America\"), # America\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=year&region=142\", \"Asia\"), # Asia\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=year&region=150\", \"Europe\"), # Europe\n",
        "         (\"https://www.numbeo.com/cost-of-living/region_rankings.jsp?title=year&region=009\", \"Oceania\") # Oceania\n",
        "]\n",
        "\n",
        "# Collecting links for regions\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Continent', 'Region', \n",
        "                                        'Cost_of_Living_Index', 'Rent_Index',\n",
        "                                        'Cost_of_Living_Plus_Rent_Index', \n",
        "                                        'Groceries_Index', \n",
        "                                        'Restaurant_Price_Index', \n",
        "                                        'Local_Purchasing_Power_Index', 'Year', \n",
        "                                        'Month', 'Day', 'Date'])\n",
        "\n",
        "years_list = ['2021-mid', '2021', '2020-mid', '2020', '2019-mid', '2019', \n",
        "              '2018-mid', '2018', '2017-mid', '2017', '2016-mid', '2016', \n",
        "              '2015-mid', '2015', '2014-mid', '2014', '2013', '2012', \n",
        "              '2011', '2010', '2009']\n",
        "url_list = []\n",
        "\n",
        "for year in years_list:\n",
        "    for (i, continent) in links:\n",
        "        res = requests.get(i.replace(\"year\", year))\n",
        "        soup = BeautifulSoup(res.text)\n",
        "        try:\n",
        "            spans = soup.find(\"div\", attrs={\"class\": \"select_region_links\"}).find_all(\"span\", attrs={\"class\": \"nobreak\"})\n",
        "        except Exception as e:\n",
        "            # Oceania doesn't have any regions\n",
        "            print(e)\n",
        "            print(i)\n",
        "        for span in spans:\n",
        "            url = span.find(\"a\", href=True)['href']\n",
        "            url_list.append(url)\n",
        "print(url_list)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oJgOJzxjNVoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_list"
      ],
      "metadata": {
        "id": "llNrTq3rioe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Continent', 'Region', \n",
        "                                        'Cost_of_Living_Index', 'Rent_Index',\n",
        "                                        'Cost_of_Living_Plus_Rent_Index', \n",
        "                                        'Groceries_Index', \n",
        "                                        'Restaurant_Price_Index', \n",
        "                                        'Local_Purchasing_Power_Index', 'Year', \n",
        "                                        'Month', 'Day', 'Date', 'URL'])\n",
        "for url in url_list:\n",
        "    resp = requests.get(url)\n",
        "    print(url)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    \n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    df['Continent'] = continent\n",
        "    df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df)\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "-tZJi40M_oCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe[final_dataframe.Year == 2015]"
      ],
      "metadata": {
        "id": "pzAJnoEn_5E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correcting the Continent\n",
        "\n",
        "\n",
        "def get_continent(x):\n",
        "    if \"Africa\" in x:\n",
        "        return \"Africa\"\n",
        "    elif \"America\" in x:\n",
        "        return \"America\"\n",
        "    elif \"Oceania\" in x:\n",
        "        return \"Oceania\"\n",
        "    elif \"Asia\" in x:\n",
        "        return \"Asia\"\n",
        "    else:\n",
        "        return \"Europe\"\n",
        "\n",
        "final_dataframe['Continent'] = final_dataframe['Region'].apply(lambda x: get_continent(x))"
      ],
      "metadata": {
        "id": "TPeMo5Py_58-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe[(final_dataframe.City == \"Aachen\") & (final_dataframe.duplicated() == True)].sort_values(by=\"City\")"
      ],
      "metadata": {
        "id": "V2wjArKCEB-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "Xdzq8pp_EC4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.drop_duplicates(subset=['City', 'Country', 'Continent', 'Region', 'Year', 'Month', 'Day', 'Date'])"
      ],
      "metadata": {
        "id": "xCbBnc9XSZsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Cost_of_living_index.csv\", index=False)"
      ],
      "metadata": {
        "id": "QghGRLqhT-Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "property_url_list = [i.replace(\"cost-of-living\", \"property-investment\") for i in url_list]"
      ],
      "metadata": {
        "id": "ZwjS5kCJXkWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Property index\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Continent', 'Region', \n",
        "                                        'Price_To_Income_Ratio',\n",
        "                                        'Gross_Rental_Yield_City_Centre',\n",
        "                                        'Gross_Rental_Yield_Outside_of_Centre',\n",
        "                                        'Price_To_Rent_Ratio_City_Centre',\n",
        "                                        'Price_To_Rent_Ratio_Outside_Of_City_Centre',\n",
        "                                        'Mortgage_As_A_Percentage_Of_Income',\n",
        "                                        'Affordability_Index', 'Year', \n",
        "                                        'Month', 'Day', 'Date', 'URL'])\n",
        "for url in property_url_list:\n",
        "    resp = requests.get(url)\n",
        "    print(url)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    \n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    df['Continent'] = continent\n",
        "    df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yQCJ-uH8Ugy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe['Continent'] = final_dataframe.Region.apply(lambda x: get_continent(x))"
      ],
      "metadata": {
        "id": "H2tCoY-aUpsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Property_price_index.csv\", index=False)"
      ],
      "metadata": {
        "id": "_FIeDAuBYemc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe"
      ],
      "metadata": {
        "id": "YaQiAkOaYlv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Property price index by country\n",
        "\n",
        "# Property index\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'Country', \n",
        "                                        'Price_To_Income_Ratio',\n",
        "                                        'Gross_Rental_Yield_City_Centre',\n",
        "                                        'Gross_Rental_Yield_Outside_of_Centre',\n",
        "                                        'Price_To_Rent_Ratio_City_Centre',\n",
        "                                        'Price_To_Rent_Ratio_Outside_Of_City_Centre',\n",
        "                                        'Mortgage_As_A_Percentage_Of_Income',\n",
        "                                        'Affordability_Index', 'Year', \n",
        "                                        'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/property-investment/rankings_by_country.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    print(df)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    # df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    # df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n"
      ],
      "metadata": {
        "id": "8_qKq8Oigeay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Property_price_index_by_country.csv\", index=False)"
      ],
      "metadata": {
        "id": "96BjaG3AiV_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quality of life index by country and city\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Quality_of_Life_Index', \n",
        "                                        'Purchasing_Power_Index', \n",
        "                                        'Safety_Index', 'Health_Care_Index', \n",
        "                                        'Cost_of_Living_Index', \n",
        "                                        'Property_Price_to_Income_Ratio', \n",
        "                                        'Traffic_Commute_Time_Index', \n",
        "                                        'Pollution_Index', 'Climate_Index', \n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/quality-of-life/rankings.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    print(df.columns)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v9CpokiKjulV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "omu869wJlm3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Quality_of_life_index_by_city.csv\", index=False)"
      ],
      "metadata": {
        "id": "sTEeyURgnI56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quality of life index by country\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'Country', \n",
        "                                        'Quality_of_Life_Index', \n",
        "                                        'Purchasing_Power_Index', \n",
        "                                        'Safety_Index', 'Health_Care_Index', \n",
        "                                        'Cost_of_Living_Index', \n",
        "                                        'Property_Price_to_Income_Ratio', \n",
        "                                        'Traffic_Commute_Time_Index', \n",
        "                                        'Pollution_Index', 'Climate_Index', \n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/quality-of-life/rankings_by_country.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    print(df.columns)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    # df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    # df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2mgRVzCOo86J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Quality_of_life_index_by_country.csv\", index=False)"
      ],
      "metadata": {
        "id": "6Y6FmL5StTZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crime index by country and city\n",
        "\n",
        "# Quality of life index by country and city\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Crime_Index', 'Safety_Index', \n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/crime/rankings.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EWTBlEv-tWay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Crime_index_by_city.csv\", index=False)"
      ],
      "metadata": {
        "id": "I0xwLRInwP76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crime index by country\n",
        "\n",
        "# Quality of life index by country\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'Country', \n",
        "                                        'Crime_Index', 'Safety_Index', \n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/crime/rankings_by_country.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join(col.split(\" \"))}, inplace=True)\n",
        "    print(df.columns)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    # df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    # df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "XGkXNh5gwf1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Crime_index_by_country.csv\", index=False)"
      ],
      "metadata": {
        "id": "0p2yGMU6w_14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Health care index by country and city\n",
        "\n",
        "# Crime index by country and city\n",
        "\n",
        "# Quality of life index by country and city\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'City', 'Country', \n",
        "                                        'Health_Care_Index', 'Health_CareExp_Index',\n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/health-care/rankings.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join([i.replace(\".\", \"\") for i in col.split(\" \")])}, inplace=True)\n",
        "    \n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sA1toc7NyAgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Health_care_index_by_city.csv\", index=False)"
      ],
      "metadata": {
        "id": "KhNA6pYIzbJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Health index by country\n",
        "\n",
        "final_dataframe = pd.DataFrame(columns=['Rank', 'Country', \n",
        "                                        'Health_Care_Index', 'Health_CareExp_Index',\n",
        "                                        'Year', 'Month', 'Day', 'Date', 'URL'])\n",
        "\n",
        "url = \"https://www.numbeo.com/health-care/rankings_by_country.jsp?title=\"\n",
        "for year in years_list:\n",
        "    resp = requests.get(url + year)\n",
        "    print(url + year)\n",
        "    soup1 = BeautifulSoup(resp.text)\n",
        "    # years_list = [i['value'] for i in soup1.find_all(\"form\", attrs={\"class\": \"changePageForm\"})[0].find(\"select\").find_all(\"option\")]\n",
        "    # print(resp.text)\n",
        "    table = soup1.find(\"table\", attrs={\"id\": \"t2\"})\n",
        "    df = pd.read_html(str(table))[0]\n",
        "    # print(df.columns)\n",
        "    # break\n",
        "    # print(table)\n",
        "    # Clean columns\n",
        "    for col in df.columns:\n",
        "        df.rename(columns={col: \"_\".join([i.replace(\".\", \"\") for i in col.split(\" \")])}, inplace=True)\n",
        "    print(df.columns)\n",
        "    # Correct Rank\n",
        "    df.reset_index(inplace=True)\n",
        "    df['Rank'] = df['index']\n",
        "    df['Rank'] = df['Rank'].apply(lambda x: x + 1)\n",
        "    df.drop(columns=['index'], inplace=True)\n",
        "    # year = url.split(\"?\")[-1].split(\"&\")[0].split(\"=\")[-1]\n",
        "    if \"mid\" in year:\n",
        "        year = int(year.split(\"-\")[0].strip())\n",
        "        month = 6\n",
        "    else:\n",
        "        year = int(year)\n",
        "        month = 1\n",
        "    # Add month year and day\n",
        "    df['Year'] = year\n",
        "    df['Month'] = month\n",
        "    df['Day'] = 1\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])\n",
        "    # Add country and continent\n",
        "    # df['Country'] = df['City'].apply(lambda x: x.split(\",\")[-1].strip())\n",
        "    # df['City'] = df['City'].apply(lambda x: x.split(\",\")[0].strip())\n",
        "    # df['Continent'] = continent\n",
        "    # df['Region'] = soup1.find(\"h1\").text.split(\":\")[0].strip()\n",
        "    df['URL'] = url\n",
        "    # print(df, df.columns, df.loc[0])\n",
        "    # break\n",
        "    final_dataframe = final_dataframe.append(df)\n",
        "\n"
      ],
      "metadata": {
        "id": "0UVI0fyhy3mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataframe.to_csv(\"Health_index_by_country.csv\", index=False)"
      ],
      "metadata": {
        "id": "xItaOCZq1476"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "files=os.listdir(\"/content/\")\n",
        " \n",
        "# iterating over all the files in\n",
        "# the source directory\n",
        "for fname in files:\n",
        "    if \".csv\" in fname:\n",
        "        shutil.copy2(os.path.join(\"/content/\",fname), \"/content/drive/MyDrive/Indicator_of_success_dataset/\")"
      ],
      "metadata": {
        "id": "RP9NHJ9r1WOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VQK56LJ01xmZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}